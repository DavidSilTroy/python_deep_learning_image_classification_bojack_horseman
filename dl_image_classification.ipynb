{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Intelligence, Thomas More Geel 2022-2023\n",
    "## Task: Deep Learning Image Classification\n",
    "#### by David Silva Troya\n",
    "This code is also on [my github](https://github.com/DavidSilTroy/python_deep_learning_image_classification_bojack_horseman)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scrape together your own image dataset:\n",
    "\n",
    "<p>\n",
    "    The dataset in this Image Classification will be about <b>Bojack Horseman</b>.\n",
    "</p>\n",
    "<p>\n",
    "    The data will be dowloaded using a python script that allows to search the data from bing images:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first all the libraries needed to scrape the data\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Now, the next code was modified by David Silva Troya, but belongs to:\n",
    "</p>\n",
    "\n",
    "[stackoverflow](https://stackoverflow.com/questions/64226325/is-there-a-way-i-can-download-images-from-any-search-engine-with-a-code-like-thi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_at_bing(search, to_folder):\n",
    "    \"\"\"This code was modified \n",
    "    by David Silva Troya, but \n",
    "    the real one was here: \n",
    "    https://stackoverflow.com/questions/64226325/is-there-a-way-i-can-download-images-from-any-search-engine-with-a-code-like-thi \"\"\"\n",
    "    \n",
    "    # search = input(\"Search for: \")\n",
    "    \n",
    "    url = \"https://www.bing.com/images/search\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:80.0) Gecko/20100101 Firefox/80.0\"\n",
    "    }\n",
    "    params = {\"q\": search, \"form\": \"HDRSC2\", \"first\": \"1\", \"scenario\": \"ImageBasicHover\"}\n",
    "    r = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    links = soup.find_all(\"div\", {\"class\": \"img_cont hoff\"})\n",
    "\n",
    "    for data in soup.find_all(\"a\", {\"class\": \"iusc\"}):\n",
    "        json_data = json.loads(data[\"m\"])\n",
    "        img_link = json_data[\"murl\"]\n",
    "        img_object = requests.get(img_link, headers=headers)\n",
    "        title = img_link.split(\"/\")[-1]\n",
    "        # print(\"Getting: \", img_link)\n",
    "        # print(\"Title: \", title + \"\\n\")\n",
    "\n",
    "        try:\n",
    "            img = Image.open(BytesIO(img_object.content))\n",
    "            img_path =f'./photos/{to_folder}/' \n",
    "\n",
    "            if not os.path.exists(img_path):\n",
    "                os.makedirs(img_path)\n",
    "                print(f'folder created for {to_folder}')\n",
    "\n",
    "            img.save(img_path + title)\n",
    "        \n",
    "        except:\n",
    "            #Because sometimes is just not possible to get the image.\n",
    "            print(f'Not Possible to download one image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    This is the code to get the images from the 5 different characters of Bojack Horseman\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from bojack:\n",
      "folder created for bojack\n",
      "Not Possible to download one image\n",
      "Not Possible to download one image\n",
      "Not Possible to download one image\n",
      "Not Possible to download one image\n",
      "Not Possible to download one image\n",
      "Not Possible to download one image\n",
      "Not Possible to download one image\n"
     ]
    }
   ],
   "source": [
    "#caracters to find as dictionary so a folder can be created with the key name\n",
    "cast = {\n",
    "    'bojack' : 'bojack horseman',\n",
    "    'carolyn' : 'princess carolyn ',\n",
    "    'diane' : 'diane nguyen',\n",
    "    'peanutbutter' : 'mr. peanutbutter',\n",
    "    'todd' : 'todd chavez',\n",
    "}\n",
    "#taking all the keys from the dictionary\n",
    "cast_list = list(cast)\n",
    "\n",
    "\n",
    "#for the UI /now deactivated for the notebook\n",
    "#print(f'From the option in {cast_list}')\n",
    "\n",
    "\n",
    "character = \"\"\n",
    "\n",
    "while True:\n",
    "    #for the UI /now deactivated for the notebook\n",
    "    # number = input(f'Select a number from 0 to {len(cast_list)-1}: \\n')\n",
    "    number = 0 #here we just select the index of the list keys from the cast\n",
    "\n",
    "    #this \"try\" is just to confirme the user wrote a number\n",
    "    try:\n",
    "        number = int(number)\n",
    "        if number>=len(cast_list) or number<0:\n",
    "            print('Wrong number')\n",
    "        else:\n",
    "            character = cast_list[number]\n",
    "            break\n",
    "    except:\n",
    "        print(f'Please, write a number of the list')\n",
    "\n",
    "#displaying what character was selected\n",
    "print(f'from {character}:')\n",
    "\n",
    "#Different options of searching to get different and more images\n",
    "search_at_bing(cast[character],character)\n",
    "search_at_bing(f'{cast[character]} happy',character)\n",
    "search_at_bing(f'{cast[character]} sad',character)\n",
    "search_at_bing(f'{cast[character]} only',character)\n",
    "search_at_bing(f'{cast[character]} normal',character)\n",
    "search_at_bing(f'{cast[character]} season 1',character)\n",
    "search_at_bing(f'{cast[character]} season 2',character)\n",
    "search_at_bing(f'{cast[character]} season 3',character)\n",
    "search_at_bing(f'{cast[character]} season 4',character)\n",
    "search_at_bing(f'{cast[character]} season 5',character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After to run the code above and change the number of character to be downloaded, the result is:\n",
    "\n",
    "The data is organized by folders\n",
    "<p style=\"text-align: center;\"> \n",
    "    <img src=\"./assets//notebook_imgs/data_got_from_scrape.png\"  style=\"width: 50%; text-align: center;\"/>\n",
    "</p>\n",
    "\n",
    "But all this is a dirty data, which means that it won't really helps to classify the different characters. The main reason is that some of the characters are in the same image for every different character:\n",
    "\n",
    "<p style=\"text-align: center;\"> \n",
    "    <img src=\"./assets//notebook_imgs/dirty_data.png\"  style=\"width: 50%; text-align: center;\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data into a training and test set:\n",
    "\n",
    "<p>\n",
    "    Impressibly this part is one of the parts that takes more time, cleaning the data is actually quite easy but even taken a little time for one image, it results is a long time for the big amount of images\n",
    "</p>\n",
    "\n",
    "\n",
    "<p>\n",
    "    So, a little cleaning of the data and the result is:\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: center;\"> \n",
    "    <img src=\"./assets//notebook_imgs/better_data.png\"  style=\"width: 50%; text-align: center;\"/>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    Now all the folder only have the images for one character:\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: center;\"> \n",
    "    <img src=\"./assets//notebook_imgs//data_got_after_clean.png\"  style=\"width: 50%; text-align: center;\"/>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    And the last part was split the images for the training(90 images) and the testing(20 images):\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: center;\"> \n",
    "    <img src=\"./assets//notebook_imgs//test_training.png\"  style=\"width: 50%; text-align: center;\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Design a CNN network with some regularisation options:\n",
    "\n",
    "<p>\n",
    "    Now the fun part comes:\n",
    "</p>\n",
    "\n",
    "\n",
    "Starting with the most important, the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install scipy\n",
    "\n",
    "# importing the Keras libraries and packages\n",
    "from tensorflow import keras #we need keras from tensorflow\n",
    "from keras.models import Sequential # to initialise our neural network model as a sequential network\n",
    "from keras.layers import Conv2D # to perform the convolution operation i.e the first step of a CNN\n",
    "from keras.layers import MaxPooling2D # used for the pooling operation\n",
    "from keras.layers import Flatten # used for Flattening. Flattening is the process of converting all the resultant 2 dimensional arrays into a single long continuous linear vector\n",
    "from keras.layers import Dense # used to perform the full connection of the neural network\n",
    "from keras.layers import Dropout # used to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "#50 filters of 3x3 each. Taking images of 64x64 pixels with 3 stands(RGB) with a ReLu activation function\n",
    "model.add(Conv2D(50, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "#Reducing the size of the image with a MaxPooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#random elimination of some conections between layers => 0.2 is 20% of the conections. This to prevent overfitting. We don't want rockstars conections.\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#adding a second Convolution (repeating previous steps):\n",
    "model.add(Conv2D(50, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#and why not adding another Convolution (repeating previous steps):\n",
    "model.add(Conv2D(50, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#converting pooled images into a continuous vector\n",
    "model.add(Flatten())\n",
    "\n",
    "#function to add a fully connected layer. The units are the number of nodes that should be presented in this hidden layer. For the output layer: we want 5 different outputs\n",
    "model.add(Dense(activation=\"relu\", units=5))\n",
    "\n",
    "# compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just check some parameters to know how the whole model looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "(None, 64, 64, 3)\n",
      "Output:\n",
      "(None, 5)\n",
      "\n",
      "Summary:\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 62, 62, 50)        1400      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 31, 31, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 31, 31, 50)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 29, 29, 50)        22550     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 12, 12, 50)        22550     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 6, 6, 50)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 6, 6, 50)          0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1800)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 9005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,505\n",
      "Trainable params: 55,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Input:')\n",
    "print(model.input_shape)\n",
    "print('Output:')\n",
    "print(model.output_shape)\n",
    "print('')\n",
    "print('Summary:')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train your model, but don't overfit (plot the training and validation/test error)\n",
    "\n",
    "<p>\n",
    "    Now lets load the data for the training and test:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 446 images belonging to 5 classes.\n",
      "Found 95 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   rotation_range = 90)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./photos/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('./photos/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train the model with the 90 images for each character. \n",
    "So we use a number of training images that is used during every step (step_per_epoch) and the the number of steps (epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "12/12 [==============================] - 3s 258ms/step - loss: -15.0896 - accuracy: 0.2225 - val_loss: -15.0887 - val_accuracy: 0.2632\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 3s 232ms/step - loss: -14.9299 - accuracy: 0.2277 - val_loss: -15.0887 - val_accuracy: 0.2632\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 3s 232ms/step - loss: -15.3291 - accuracy: 0.2461 - val_loss: -15.0887 - val_accuracy: 0.2632\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 3s 232ms/step - loss: -15.3690 - accuracy: 0.2016 - val_loss: -15.0887 - val_accuracy: 0.2632\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 3s 223ms/step - loss: -15.7682 - accuracy: 0.2277 - val_loss: -15.0887 - val_accuracy: 0.2632\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 3s 229ms/step - loss: -15.8880 - accuracy: 0.2277 - val_loss: -15.0887 - val_accuracy: 0.2632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a85943070>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(training_set,\n",
    "                    steps_per_epoch = 12,\n",
    "                    epochs = 6,\n",
    "                    validation_data = test_set)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeap.. the accuracy is not good at all. I'm still trying to understand why...\n",
    "So I am stuck here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./saved_models/modelcifar-10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "[[3651.7058 4181.6455 3961.5227 4307.317  4332.819 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# test_image = image.load_img(\"./photos/single_image/BoJack-Horseman-1.jpg\", target_size = (64, 64))\n",
    "test_image = image.load_img(\"./photos/single_image/BoJack-Horseman.png\", target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare your model's performance to Google's Teachable Machine, using the same training dataset\n",
    "\n",
    "<p>\n",
    "    Still in progress...\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some websites that helps me to make this program:\n",
    "\n",
    "-https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "\n",
    "-https://stackoverflow.com/questions/72383347/how-to-fix-it-attributeerror-module-keras-preprocessing-image-has-no-attribu\n",
    "\n",
    "-https://stackoverflow.com/questions/70961988/layer-count-mismatch-when-loading-weights-from-file-model-expected-106-layers\n",
    "\n",
    "-https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "-https://stackoverflow.com/questions/59864408/tensorflowyour-input-ran-out-of-data\n",
    "\n",
    "-https://towardsdatascience.com/data-augmentation-compilation-with-python-and-opencv-b76b1cd500e0\n",
    "\n",
    "-https://neptune.ai/blog/data-augmentation-in-python\n",
    "\n",
    "-https://www.kaggle.com/code/prateek0x/multiclass-image-classification-using-keras\n",
    "\n",
    "-https://stackoverflow.com/questions/67960945/keras-and-tensorflow-on-python-valueerror-input-data-in-numpyarrayiterator\n",
    "\n",
    "-https://pub.towardsai.net/multiclass-image-classification-hands-on-with-keras-and-tensoflow-e1cf434f3467\n",
    "\n",
    "-https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/\n",
    "\n",
    "-https://www.geeksforgeeks.org/python-image-classification-using-keras/#:~:text=Image%20classification%20is%20a%20method,of%20the%20model%20using%20VGG16\n",
    "\n",
    "-https://keras.io/api/preprocessing/image/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env_AI_T3_DL': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42297c47341c54cfc82c4c1358bf758529eb0127a943ca746606a14b314a6e5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
